<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Chandler Kwok"><meta name="copyright" content="Chandler Kwok"><title>熟能生巧 | 郭大瞎のBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://i.loli.net/2020/05/05/r8BpGnwzsW25QSN.jpg"></div><div class="author-info__name text-center">Chandler Kwok</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">44</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">48</span></a></div></div></div><nav id="nav" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlgy1get1mqmvxij31hc0u0q7i.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">郭大瞎のBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">郭大瞎のBlog</div><div id="site-sub-title">熟能生巧</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/05/13/redis-cli-cluster-mode/">redis-cli -c 的误解</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-13</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/redis-cluster/">redis cluster</a></span><div class="content"><p>内部系统使用的一个AWS Elasticcache集群，不知不觉就扩容到8个node节点。被迫从AWS Elasticcache Redis上导出snapshot文件到S3，准备用作做分析。</p>
<p>分析工具是一个python实现的rbdtools </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install rbdtools</span><br><span class="line">rdb -c memory /tmp/dump.rdb</span><br></pre></td></tr></table></figure>

<p>实际上导出的中共有8个rbd文件，分析结果会生成csv文件。分析后，发现是大量登陆token，没有设置ttl。开发后续核对代码，才知道登陆时设置ttl了，但在更新权限时，忘记带上ttl值。于是日积月累产生越来越多无用的数据。</p>
<p>接下来就是清理了。</p>
<ul>
<li>方案一：</li>
</ul>
<p>取出没ttl的key的空闲时间，进行倒序排列，删除半年都没人访问的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -c -h 10.20.0.111 -p 6379 --scan --pattern erpToken* | xargs -r -t -n1  redis-cli -c -h 10.20.0.112 -p 6379 object idletime </span><br><span class="line">// 取出后，通过程序删除</span><br></pre></td></tr></table></figure>



<ul>
<li>方案二：</li>
</ul>
<p>通过rename命令，变更key的name。后续再清理</p>
<ul>
<li>方案三：</li>
</ul>
<p>直接清空全部 key name 为erpToken* 模式的数据。</p>
<p>然而，此处有一个坑，redis-cli -c 的cluster 模式，并不会帮你跳转到所有节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -c -h 10.20.0.118 -p 6379 --scan --pattern erpToken* </span><br><span class="line">redis-cli -c -h 10.20.0.118 -p 6379 keys erpToken* </span><br><span class="line">// 这两条命令，都只是在client连接到的节点上列出数据</span><br><span class="line"></span><br><span class="line">redis-cli -c -h 10.20.0.111 -p 6379 --scan --pattern erpToken* | xargs -r -t -n1  redis-cli -c -h 10.20.0.112 -p 6379 del</span><br><span class="line">// 其实也只是清空了其中一个节点而已。正确的做法，只能通过for循环，取出master节点，逐个连接上去清理。</span><br></pre></td></tr></table></figure>



<p>其实 redis-cli 的 -c 参数，help如下：Enable cluster mode (follow -ASK and -MOVED redirections)。所以只是针对取特定值的时候，帮助做跳转而已。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/05/05/python-virtual-enviroment/">python virtual enviroment</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-05</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/python/">python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/jupyter/">jupyter</a></span><div class="content"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟环境</span></span><br><span class="line">python -m venv .venv</span><br><span class="line"><span class="comment"># 切换到虚拟环境</span></span><br><span class="line"><span class="built_in">source</span> .venv/bin/active</span><br><span class="line"><span class="comment"># 添加环境中的python Kernel到juypter,当然下面的projectname 还是改一个合适的名称哦</span></span><br><span class="line">ipython kernel install --user --name=projectname</span><br><span class="line"><span class="comment"># 切到项目工作空间</span></span><br><span class="line"><span class="built_in">cd</span> workspace</span><br><span class="line"><span class="comment"># 运行jupyter</span></span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<p>最终就能在下图位置中，找到虚拟的环境了。如果要需要安装第三方包，jupyter也可以直接开启termial安装。用来做调试小爬虫很轻巧呢。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1geik0bstg3j30wx09wwg2.jpg" alt="image-20200506110943033"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/05/05/BeautifulSoup/">BeautifulSoup</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-05</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/python/">python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/beautifulSoup4/">beautifulSoup4</a></span><div class="content"><p>HTML说到底还是XML标记语言，因此解析XML在爬虫抓取结果后，对数据进行拆解分析，变少不了BeautifulSoup4了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">~/code/algorithm via algorithm </span><br><span class="line">➜ cat bf4.py            </span><br><span class="line"><span class="comment">#!/bin/env python3</span></span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">html_doc = <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="</span>title<span class="string">"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class="</span>story<span class="string">"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="</span>http://example.com/elsie<span class="string">" class="</span>sister<span class="string">" id="</span>link1<span class="string">"&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="</span>http://example.com/lacie<span class="string">" class="</span>sister<span class="string">" id="</span>link2<span class="string">"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="</span>http://example.com/tillie<span class="string">" class="</span>sister<span class="string">" id="</span>link3<span class="string">"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class="</span>story<span class="string">"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">soup = BeautifulSoup(html_doc, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.prettify())%                                                                                 </span><br><span class="line"></span><br><span class="line">~/code/algorithm via algorithm </span><br><span class="line">➜ python bf4.py</span><br><span class="line"></span><br><span class="line">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse<span class="string">'s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="title"&gt;&lt;b&gt;The Dormouse'</span>s story&lt;/b&gt;&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p class=<span class="string">"story"</span>&gt;Once upon a time there were three little sisters; and their names were</span><br><span class="line">&lt;a href=<span class="string">"http://example.com/elsie"</span> class=<span class="string">"sister"</span> id=<span class="string">"link1"</span>&gt;Elsie&lt;/a&gt;,</span><br><span class="line">&lt;a href=<span class="string">"http://example.com/lacie"</span> class=<span class="string">"sister"</span> id=<span class="string">"link2"</span>&gt;Lacie&lt;/a&gt; and</span><br><span class="line">&lt;a href=<span class="string">"http://example.com/tillie"</span> class=<span class="string">"sister"</span> id=<span class="string">"link3"</span>&gt;Tillie&lt;/a&gt;;</span><br><span class="line">and they lived at the bottom of a well.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p class=<span class="string">"story"</span>&gt;...&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"bf4.py"</span>, line 19, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    soup = BeautifulSoup(html_doc, <span class="string">'lxml'</span>)</span><br><span class="line">  File <span class="string">"/Users/chandler.kwok/code/algorithm/.venv/lib/python3.7/site-packages/bs4/__init__.py"</span>, line 228, <span class="keyword">in</span> __init__</span><br><span class="line">    % <span class="string">","</span>.join(features))</span><br><span class="line">bs4.FeatureNotFound: Couldn<span class="string">'t find a tree builder with the features you requested: lxml. Do you need to install a parser library?</span></span><br></pre></td></tr></table></figure>

<p>简单的按照例子，结果第一步便是报错。原因是 pip3 install beautifulsoup4 还不足以。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/27/promethues-consul/">Promethues Consul监控</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-27</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/consul/">consul</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/prometheus/">prometheus</a></span><div class="content"><p>一边在做数据库备份，一边写😭。</p>
<p>下午抽空，在K8S的Promethues上接入了consul。完成了微服务的JVM监控。</p>
<p><img src="https://i.loli.net/2020/04/27/3cHMkF9Yyd4GNaI.png" alt="image.png"></p>
<p>记录一下步骤：</p>
<ol>
<li><p>创建generic secret ，内容为Prometheus 的 consul自动发现配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ip-10-20-1-93 consul-prometheus]# cat prometheus-additional.yaml</span><br><span class="line">- job_name: 'consul-dop-dev1'</span><br><span class="line">  scrape_interval: 15s</span><br><span class="line">  consul_sd_configs:</span><br><span class="line">      - server: dop-otter-consul-dev1.dop-dev1.svc.cs-software.local:8500</span><br><span class="line">[root@ip-10-20-1-93 consul-prometheus]# kubectl create secret generic additional-scrape-configs --from-file=prometheus-additional.yaml --dry-run -oyaml &gt; additional-scrape-configs.yaml</span><br><span class="line">[root@ip-10-20-1-93 consul-prometheus]# kubectl apply -f additional-scrape-configs.yaml -n prometheus</span><br><span class="line">secret/additional-scrape-configs configured</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改CRD Prometheus </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在spec中增加additionalScrapeConfigs的定义</span></span><br><span class="line">spec:</span><br><span class="line">  additionalScrapeConfigs:</span><br><span class="line">    key: prometheus-additional.yaml</span><br><span class="line">    name: additional-scrape-configs</span><br></pre></td></tr></table></figure>
</li>
<li><p>Reload 一下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ip-10-20-1-93 consul-prometheus]# curl -X POST http://10.20.210.204:9090/-/reload</span><br></pre></td></tr></table></figure>
</li>
<li><p>Grafana 导入 <a href="https://grafana.com/grafana/dashboards/10280" target="_blank" rel="noopener"><em>Spring Boot 2.1 Statistics</em></a></p>
<p>很快看到结果。</p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/16/mysql%E9%94%81/">mysql锁</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-16</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/mysql-%E9%94%81%E6%9C%BA%E5%88%B6/">mysql 锁机制</a></span><div class="content"><p>内容仅为个人理解，我也在不断的纠正自己的理解。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 以下讨论都基于：Innodb，事务隔离机制采用RR</span></span><br><span class="line"><span class="keyword">select</span> @@global.tx_isolation;</span><br><span class="line">REPEATABLE-READ</span><br></pre></td></tr></table></figure>

<p>First Of All，Mysql数据库在事务隔离级别为RR的情况下，如果要避免幻读，就要通过间隙锁。那么如何最简单的实现间隙锁，就是通过select语句中 for update 排他锁。正常的select语句是不会加锁的。而是通过访问记录的版本链的过程，实现MVCC（多版本并发控制），也可以简单的理解为快照读，并不加锁。在select for update， 还有 insert， update， delete 的时候，就需要考虑锁机制了。另外mysql的锁，锁定的是索引，并不是数据。</p>
<h3 id="行锁算法（注意是算法哦）"><a href="#行锁算法（注意是算法哦）" class="headerlink" title="行锁算法（注意是算法哦）"></a>行锁算法（注意是算法哦）</h3><ul>
<li><p>普通行锁</p>
<p>唯一索引，且查询的记录存在</p>
</li>
<li><p>间隙锁</p>
<p>锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。</p>
<p>常见于，<strong>键值不存在条件范围内</strong>，叫做间隙（GAP），引擎会对该“间隙”加锁。</p>
</li>
<li><p>Next-key Lock（行锁&amp;间隙锁）</p>
<p>相当于两种锁的结合。锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。</p>
</li>
</ul>
<h2 id="锁的类型："><a href="#锁的类型：" class="headerlink" title="锁的类型："></a>锁的类型：</h2><p>共享锁（S）、排他锁（X）、意向共享（IS）、意向排他（IX）</p>
<p>行锁，表锁其实是锁的粒度的概念，共享锁和排它锁是具体的实现。</p>
<p>共享锁（S）： 允许其他事务来读取，但是阻止其他事务，在该行获取该行的排它锁。简单的记忆：能读不能写。共享锁的查询举例： select … lock in share mode。</p>
<p>排它锁（X）： 允许持有排它锁的事务读写数据，阻止其他事务获取该行的共享锁和排它锁。但是其他事务还是可以读的。（普通的select语句，并不影响数据查询）。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 排它锁的举例：</span></span><br><span class="line"><span class="keyword">update</span> ...</span><br><span class="line"><span class="keyword">delete</span> ...</span><br><span class="line"><span class="keyword">insert</span> ...</span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">for</span> <span class="keyword">update</span></span><br></pre></td></tr></table></figure>



<h3 id="间隙锁之举例"><a href="#间隙锁之举例" class="headerlink" title="间隙锁之举例"></a>间隙锁之举例</h3><p>前言：始终不要忘记间隙锁的目的，是为了解决幻读。所以开发工作中，要主动思考，规避在某些并发环境下，会出现幻读，常见做法便是：在sql中加入for update，或是乐观锁。在运维工作中，也要留意数据库，出现同样间隙锁的性能问题。（遇到过，数据库大量的insert 导致的间隙锁）</p>
<ol>
<li></li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/16/docker-cache/">Docker Cache</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-16</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/docker-cache/">docker cache</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/docker-build-%E5%8A%A0%E9%80%9F/">docker build 加速</a></span><div class="content"><p>Docker 镜像在build的过程中，默认会有一套缓存机制。</p>
<p>用自己的语言直白描述 ，能更容易记住呢。</p>
<ol>
<li><p>Docker 镜像默认是一层一层的叠加上去。dockerfile中的每一行，对应就是一层。</p>
</li>
<li><p>每次构建，Docker会比对每一层是否有变化，如果构建命令没有–no-cache=true 参数，默认都会尽量用上缓存。</p>
</li>
<li><p>Docker如何判断这一层是否变化呢。ADD，COPY的层，docker会去比对文件，计算文件的校验和。（校验和中不考虑最后修改和最后访问时间）。其余的层，会去比对字符串。一旦其中一层发生了变化，在此之上的所有层，都不会再用到缓存了。</p>
</li>
</ol>
<p>学了原理，当然要知道怎么优雅的使用呢：</p>
<ul>
<li>据一个🌰</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">from</span> <span class="string">centos-alpha</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">yum</span> <span class="string">update</span> <span class="string">-y</span> <span class="string">&amp;&amp;</span> <span class="string">yum</span> <span class="string">install</span> <span class="string">epel</span> <span class="string">-y</span> <span class="string">&amp;&amp;</span> <span class="string">yum</span> <span class="string">xxxx</span></span><br><span class="line"><span class="string">CMD</span> <span class="string">COMMAND</span></span><br></pre></td></tr></table></figure>

<p>如上，我们在调试dockerfile的时候，常常会多次构建，过程中，可能发现缺少依赖包，变反复修改第二层的RUN指令。</p>
<p>而yum update -y ，却是每次最耗时的指令。如果独立层单独一层，就发现速度飞快了。</p>
<ul>
<li>再举一个🌰</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="string">node-alpha</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">.</span> <span class="string">/src</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">cd</span> <span class="string">/src</span> <span class="string">&amp;&amp;</span> <span class="string">npm</span> <span class="string">install</span></span><br></pre></td></tr></table></figure>

<p>如上，第三层中，每一次npm install 会安装package.json中指定的依赖。而如果一个项目在定型后，package.json在变更的频率会非常少，于是聪明的做法是将其改为</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="string">node-alpha</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">package.json</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">npm</span> <span class="string">install</span> </span><br><span class="line"><span class="string">COPY</span> <span class="string">.</span> <span class="string">/src</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">xxxx</span></span><br></pre></td></tr></table></figure>

<p>这样，在第二层package.json文件不变的情况下，在jenkins 构建编译的时候，可以重复利用第二层。速度也随之加快多了。</p>
<p>好的，那么新的问题来了，docker 镜像在开发测试与生产环境物理距离遥远的企业中，应该如何放置呢。像现在的公司，开发测试等环节都在内部的办公机房里。而生产环境远在aws 俄勒冈。镜像的同步受网络条件制约。对此我们内部出现了多种设想。</p>
<ol>
<li><p>异地编译，生成镜像。同事说在aws环境内，单独完成生产环境的构建编译镜像封装。</p>
</li>
<li><p>镜像同步，开发测试环境，在稳定后将镜像同步到特定的仓库。改仓库再通过mirror同步到海外的registey。</p>
<p>我选择了2。原因是容器的目的之一，便是将运行环境也纳入到版本控制中，方案一存在巨大的漏洞，两次构建编译，其中存在不确定因素，所以被彻底否决。</p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/15/aws-s3-static-website/">aws s3 static website</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-15</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/aws/">aws</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/s3/">s3</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/cloudfront/">cloudfront</a></span><div class="content"><p>Aws S3 加上cloudfront，可以直接代替nginx。并且有更高的可用性。于是告诉给架构师这个方案后，就开始配置了。</p>
<ol>
<li>开bucket，设置静态托管</li>
</ol>
<p><img src="https://i.loli.net/2020/04/15/hT2kLX5bKEQNug6.png" alt="image.png"></p>
<ol start="2">
<li><p>设置bucket policy，所有资源均为public</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"Version"</span>: <span class="string">"2012-10-17"</span>,</span><br><span class="line">    <span class="attr">"Id"</span>: <span class="string">"Policy1586756429373"</span>,</span><br><span class="line">    <span class="attr">"Statement"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Sid"</span>: <span class="string">"Stmt1586756xxxx5"</span>,</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Principal"</span>: <span class="string">"*"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: <span class="string">"s3:GetObject"</span>,</span><br><span class="line">            <span class="attr">"Resource"</span>: <span class="string">"arn:aws:s3:::xxx-speedup/*"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>开始Cloudfront，限定只允许GET，HEAD 两种method。还有开启Gzip。暂时用最简单的配置。</p>
<p><img src="https://i.loli.net/2020/04/15/emMT4YEbvzoxFZA.png" alt="image.png"></p>
</li>
<li><p>上传资源到S3</p>
<p>Jenkins plugin 本有一个S3插件，可是依赖maven 3.5版本，由于现在开发团队在用3.4，于是放弃该插件。</p>
<p>改用传统的步骤：jenkins执行shell，</p>
<p>AWS_ACCESS_KEY_ID与AWS_SECRET_ACCESS_KEY，就取巧通过参数化构建过程带入吧！恰巧这个插件会将参数设置为环境变量，所以就这么办了。（Pipeline + Credentials会更加优雅）</p>
<p>注意上传前，自己先gzip一下，因为S3可是不会自动帮你压缩的。当然这个也可以通过event驱动Lambda来优雅实现。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find ./ -type f -exec gzip "&#123;&#125;" \; -exec mv "&#123;&#125;.gz" "&#123;&#125;" \;</span><br><span class="line">aws s3  mv  ./  s3://xxx-speedup  --recursive --exclude ".git/*"   --content-encoding "gzip"</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/04/15/wA5IPakjCm2F8fQ.png" alt="image.png"></p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/14/why-docker/">WHY docker？</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-14</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/docker/">docker</a></span><div class="content"><p>Docker/Kubernetes 天天弄，可是又有多少底层技术深刻的记在心里呢。</p>
<p>原理：COW （Copy On Write）</p>
<p>Docker 镜像由多个只读层叠加而成，启动容器时，Docker会加载只读镜像层，并在镜像栈顶部添加一个读写成。如果运行的容器修改了一个已经存在的文件。那么文件就会从只读层复制到读写层，该文件的只读版本依然存在。</p>
<p>理解原理后，便是要思考如何运用到工作中🥶。</p>
<ul>
<li><p>容器最后的读写层，可能一般包含了修改的文件。 所以应该避免将容器，docker commit 的方式提交到registry。</p>
</li>
<li><p>docker ps -s 可以看到容器总共的size（含读写层），以及读写层的size。</p>
</li>
<li><p>docker history 看到的 某些层为missing，没有标注ID。其实是因为这些层不在这台电脑上封装。</p>
<p><img src="https://i.loli.net/2020/04/17/PuK8WE9sbGhyBzd.png" alt="image.png"></p>
</li>
</ul>
<p>base 镜像 - Linux最小安装的Linux发行版</p>
<ul>
<li><p>在Dockerhub上拉去一个centos镜像，看到只有200mb。困惑。其实这是因为docker镜像在运行时，使用的是docker宿主机的kernel。Linux操作系统由内核空间和用户空间组成。</p>
<p><img src="https://i.loli.net/2020/04/17/LgZ3wEkXtsrhCnj.png" alt="image.png"></p>
</li>
</ul>
<h3 id="My-Question"><a href="#My-Question" class="headerlink" title="My Question"></a>My Question</h3><p>那么相同的两个镜像，做了少许改动后，push到harbor，客户端需要把镜像每一层都重新推到harbor上吗？答案是no。registry 会做一个判断，如果层的校验值一致，其实会提示Layer already exists。直接跳过。</p>
<p><img src="https://i.loli.net/2020/04/17/r8MzLThsmaYwNi5.png" alt="image.png"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/13/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D/">网络地址分配</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-13</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/ipv4/">ipv4</a></span><div class="content"><p>A类地址： 1.0.0.0 ～ 127.255.255.255</p>
<p>B类地址：128.0.0.0 ～ 191.255.255.255</p>
<p>C类地址：192.0.0.0 ～ 223.255.255.255</p>
<p>D类地址：224.0.0.0 ～ 239.255.255.255 （用作广播用途） </p>
<p>E类地址：240.0.0.0 ～ 255.255.255.255（保留）</p>
<p>这就将全球的所有ipv4地址划分成了5类，那么又再其中的部分划出来，给局域网使用。</p>
<p>A类地址中的：  10.0.0.0/8</p>
<p>B类地址中的： 127.16.0.0/12</p>
<p>C类地址中的： 192.168.0.0/16 </p>
<p>接下来快速计算一下： 192.168.1.0/255.255.255.252 ，即掩码为30</p>
<blockquote>
<p>网络地址：192.168.0000 0001.0</p>
<p>掩码：1111 1111.1111 1111.1111 1111.1111 1100</p>
<p>与运算后结果，即为网络IP：192.168.1.0</p>
<p>根据判断两个ip是否在同一个子网的方法：与掩码运算后，结果一致，就是同一个子网内。</p>
<p>这么推理。</p>
<p>最小IP： 192.168.1.0</p>
<p>最大IP：192.168.1.255</p>
<p>当然最大最小，分别留作网络ID还有广播地址。</p>
<p>子网数：</p>
</blockquote>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/13/mysql%E4%BA%8B%E5%8A%A1/">MySQL事务隔离级别</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-13</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/mysql/">mysql</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/">事务隔离级别</a></span><div class="content"><ol>
<li><p>什么是<strong>脏读</strong>： 读到没有commit的数据</p>
</li>
<li><p>什么是<strong>不可重复读</strong>：同一个事务中，两次读取到的数据不一样。</p>
</li>
<li><p>什么是<strong>幻读</strong>： <del>同一个事务中，两次读取到的数据不一样。</del>这个流程看起来和不可重复读差不多，但幻读强调的集合的增减，而不是单独一条数据的修改。最常见的场景便是</p>
</li>
</ol>
<p>事务的隔离级别</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select @@global.tx_isolation;</span><br></pre></td></tr></table></figure>

<p>级别逐级别提高，越高数据隔离的越彻底。可是代价是付出性能。</p>
<ul>
<li><p>value 为0</p>
<p>读未提交（Read Uncommitted），在这个级别下，所有事务都能看到其他未提交的事务的数据，基本很少用到。</p>
</li>
<li><p>value 为1</p>
<p>一个事务只能看见已经提交事务所做的改变。解决脏读的问题，存在不可重复读，幻读的问题。</p>
</li>
<li><p>可重复读 REPEATABLE-READ | 2</p>
<p>MySQL默认的级别，解决脏读，不可重复读。但是存在幻读的。接下来就是要讨论如何避免了。</p>
</li>
<li><p>序列化 SERIALIZABLE | 3</p>
<p>强迫事务排序，串行执行事务，从而杜绝上面的所有问题，但是会带来大量的等待，基本没有使用。</p>
</li>
</ul>
<p>在RR（READTABLE-READ）级别下，如何避免幻读，答案是显式加锁。</p>
<p>简单的场景：</p>
<p>A 事务：查询表是否存在id=10000，如果无，就插入数据。</p>
<p>就在插入的前一刻，另外一个事务插入了id=10000的数据，此刻A事务就会莫名收到数据已经存在的错误，也无法插入成功。这就是典型的幻读了。如何解决呢，用SELECT FOR UPDATE，无论数据是否存在，都会被加上锁。（当记录不存在的时候，mysql 会给索引加上gap间隙锁，对此可以模拟一下哦）</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlgy1get1mqmvxij31hc0u0q7i.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2021 By Chandler Kwok</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>